# FEDI-WATCH concept doc

This is just an idea, and might not be a good one.  I'm setting this up to get feedback. Contact me at [@bonkerfield@sigmoid.social](https://sigmoid.social/@bonkerfield)  with your thoughts.

### Problem
We want everyone who joins Mastodon to feel safe when they get here--no matter what instance they happen to land on.  But for large instances, there have been moderation problems internal to that server.  There are ways that individuals can upload block list domains etc, but that puts the onus on the new person who is just getting acquainted with Mastodon.  There should be more ways to protect new people from bad actors who want to threaten, intimidate and generally make others feel unsafe.

### Question
Can we protect and welcome everyone who joins Mastodon with an external solution?

### Potential Roadblock
The fediverse is set up to be divided into separate servers with individual moderators in control. That's good to decentralize control, but it makes it really hard to provide protection for new people.  We want to make a solution that offers some kind of help without having access to true moderation tools on the server side.

### Idea
Automate flagging toxic/racist/sexist posts for a network of *helpers* who are *caregivers* that reply and help the person who is being attacked to deal with the situation.  We can offer them guidance for blocking the bad actors, and we can help them know that the rest of us want them here.  We are caregivers because we are there to show we care and support new folks. We're not moderators.


### Example Walkthrough
1. A new person joins one of the large instances.
2. They post something about their life.
3. We watch for replies to their post, and run it through a few automated checks to see if there are any negative words or more complex toxic or trolling discussions.
4. If any replies are flagged, a message is sent to the caregiver queue for one of the on-shift volunteers to address.
5. A caregiver joins the thread and provides help with blocking, talks to the attacked person, and offers them kind words to make up for the pain that others have inflicted on them.
6. We send our own reports to server admins to get things noticed as fast as possible
7. If someone is on a server with bad administration policies, we help them quickly migrate to someplace safe.

### Other thoughts
The big question is can we get this to work with many new users per day? That is a lot of volunteer commitment.

Ideally all of this could run on the server side and help with decentralized community moderation, but that takes a lot of integration and there are people being harmed every day.  This is an attempt to help with this problem now.
